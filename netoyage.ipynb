{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1 - Imports & Configuration\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Input source file \n",
    "FILE_PATH = r\"C:\\Users\\khali\\OneDrive\\Pictures\\Desktop\\Data file for students.xlsx\"\n",
    "\n",
    "# Output file \n",
    "OUTPUT_FILE = os.path.join(os.path.dirname(FILE_PATH), \"financial_kpis.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da865a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PART 2 - Load and Clean Sheets\n",
    "\n",
    "# Load all sheets from Excel\n",
    "dfs = pd.read_excel(FILE_PATH, sheet_name=None)\n",
    "\n",
    "# Remove unnamed/empty columns\n",
    "for sheet in dfs.keys():\n",
    "    dfs[sheet] = dfs[sheet].loc[:, ~dfs[sheet].columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "# Extract key sheets\n",
    "gl_df = dfs[\"GL\"].copy()\n",
    "chart_df = dfs[\"Chart of Accounts\"].copy()\n",
    "calendar_df = dfs[\"Calendar\"].copy()\n",
    "territory_df = dfs[\"Territory\"].copy()\n",
    "\n",
    "# Convert Date to datetime and add Year column\n",
    "gl_df[\"Date\"] = pd.to_datetime(gl_df[\"Date\"], errors=\"coerce\")\n",
    "gl_df[\"Year\"] = gl_df[\"Date\"].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3 - Enrich General Ledger\n",
    "\n",
    "\n",
    "# Merge GL with Chart of Accounts to get Class, Report, etc.\n",
    "gl_df = gl_df.merge(chart_df, on=\"Account_key\", how=\"left\")\n",
    "\n",
    "# Merge GL with Territory to get Region / Country\n",
    "gl_df = gl_df.merge(territory_df, on=\"Territory_key\", how=\"left\")\n",
    "\n",
    "# Merge GL with Calendar to get Year, Quarter, Month, Day\n",
    "gl_df = gl_df.merge(calendar_df, on=\"Date\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3588fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns after cleaning: ['EntryNo', 'Date', 'Territory_key', 'Account_key', 'Details', 'Amount', 'Year', 'Report', 'Class', 'SubClass', 'SubClass2', 'Account', 'SubAccount', 'Country', 'Region', 'Quarter', 'Month', 'Day', 'Report_norm', 'Class_norm', 'SubClass_norm', 'SubClass2_norm', 'Account_norm', 'SubAccount_norm', 'Details_norm']\n",
      "✅ Indicators computed:\n",
      "      Sales(CA)     OPEX   EBITDA  Interest_Tax  NetIncome  WCR(BFR)    CAPEX\n",
      "Year                                                                         \n",
      "2018    2383246 -1642445   740801       -153422     306844   2438860  -993004\n",
      "2019    3968546 -2492858  1475688       -219703     439406   3757253 -1161156\n",
      "2020    5341360 -3819194  1522166       -304486     608972   1169074 -1530264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khali\\AppData\\Local\\Temp\\ipykernel_18508\\2670222018.py:42: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask_details = d[\"Details_norm\"].str.contains(CAPEX_DETAILS_PAT, regex=True, na=False)\n",
      "C:\\Users\\khali\\AppData\\Local\\Temp\\ipykernel_18508\\2670222018.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = grp.apply(lambda d: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# PART 4 - Clean Columns & Compute KPIs\n",
    "\n",
    "# Fix Year column from merges\n",
    "if \"Year_x\" in gl_df.columns:\n",
    "    gl_df = gl_df.rename(columns={\"Year_x\": \"Year\"})\n",
    "if \"Year_y\" in gl_df.columns:\n",
    "    gl_df = gl_df.drop(columns=[\"Year_y\"], errors=\"ignore\")\n",
    "\n",
    "# Keep the left side of merges\n",
    "gl_df = gl_df.rename(columns={\n",
    "    \"Report_x\": \"Report\",\n",
    "    \"Class_x\": \"Class\",\n",
    "    \"SubClass_x\": \"SubClass\",\n",
    "    \"SubClass2_x\": \"SubClass2\",\n",
    "    \"Account_x\": \"Account\",\n",
    "    \"SubAccount_x\": \"SubAccount\"\n",
    "})\n",
    "\n",
    "# Drop duplicate right-side columns\n",
    "gl_df = gl_df.drop(columns=[c for c in gl_df.columns if c.endswith(\"_y\")], errors=\"ignore\")\n",
    "\n",
    "# Normalize text columns to be robust to casing/spacing\n",
    "for col in [\"Report\", \"Class\", \"SubClass\", \"SubClass2\", \"Account\", \"SubAccount\", \"Details\"]:\n",
    "    if col in gl_df.columns:\n",
    "        gl_df[col] = gl_df[col].astype(str).str.strip()\n",
    "        gl_df[f\"{col}_norm\"] = gl_df[col].str.lower().str.strip()\n",
    "    else:\n",
    "        gl_df[f\"{col}_norm\"] = \"\"\n",
    "\n",
    "# Debug\n",
    "print(\"✅ Columns after cleaning:\", gl_df.columns.tolist())\n",
    "\n",
    "\n",
    "# CAPEX via explicit 'Details' \n",
    "CAPEX_DETAILS_PAT = r\"\\bpurchase of (equipment|intangible|intangibles)\\b\"\n",
    "\n",
    "def capex_amount(d):\n",
    "    \"\"\"Return CAPEX amount for a yearly slice d (robust).\"\"\"\n",
    "    # 1) Primary: details mention of purchases\n",
    "    mask_details = d[\"Details_norm\"].str.contains(CAPEX_DETAILS_PAT, regex=True, na=False)\n",
    "\n",
    "    # 2) Fallback: movements on PPE / Intangible Assets (when booked as purchases in GL)\n",
    "    #    This is a proxy in case Details are missing. We keep it permissive.\n",
    "    mask_ppe = d[\"Account_norm\"].isin([\"property, plant, & equipment\", \"intangible assets\"])\n",
    "\n",
    "    # Combine\n",
    "    mask_capex = mask_details | mask_ppe\n",
    "\n",
    "    return d.loc[mask_capex, \"Amount\"].sum()\n",
    "\n",
    "# ---------------- Indicators ----------------\n",
    "def compute_indicators(df):\n",
    "    \"\"\"Compute yearly financial indicators from the enriched GL dataframe.\"\"\"\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise KeyError(\"⚠️ Column 'Year' not found in dataframe.\")\n",
    "\n",
    "    grp = df.groupby(\"Year\")\n",
    "\n",
    "    out = grp.apply(lambda d: pd.Series({\n",
    "        # Sales = Trading account\n",
    "        \"Sales(CA)\": d.loc[d[\"Class\"] == \"Trading account\", \"Amount\"].sum(),\n",
    "\n",
    "        # OPEX = Operating account \n",
    "        \"OPEX\": d.loc[d[\"Class\"] == \"Operating account\", \"Amount\"].sum(),\n",
    "\n",
    "        # EBITDA = Sales + OPEX \n",
    "        \"EBITDA\": (\n",
    "            d.loc[d[\"Class\"] == \"Trading account\", \"Amount\"].sum()\n",
    "            + d.loc[d[\"Class\"] == \"Operating account\", \"Amount\"].sum()\n",
    "        ),\n",
    "\n",
    "        # Interest & Tax \n",
    "        \"Interest_Tax\": d.loc[d[\"Class\"] == \"Interest & Tax\", \"Amount\"].sum(),\n",
    "\n",
    "        # Net Income = Sales + OPEX + Non-operating + Adjusting - Interest & Tax\n",
    "        \"NetIncome\": (\n",
    "            d.loc[d[\"Class\"] == \"Trading account\", \"Amount\"].sum()\n",
    "            + d.loc[d[\"Class\"] == \"Operating account\", \"Amount\"].sum()\n",
    "            + d.loc[d[\"Class\"] == \"Non-operating\", \"Amount\"].sum()\n",
    "            + d.loc[d[\"Class\"] == \"Adjusting\", \"Amount\"].sum()\n",
    "            - d.loc[d[\"Class\"] == \"Interest & Tax\", \"Amount\"].sum()\n",
    "        ),\n",
    "\n",
    "        # WCR(BFR)\n",
    "        \"WCR(BFR)\": (\n",
    "            d.loc[(d[\"Report\"] == \"Balance Sheet\") & (d[\"SubClass2\"] == \"Current Assets\"), \"Amount\"].sum()\n",
    "            - d.loc[(d[\"Report\"] == \"Balance Sheet\") & (d[\"SubClass2\"] == \"Current Liabilities\"), \"Amount\"].sum()\n",
    "        ),\n",
    "\n",
    "        # CAPEX: robust (Details mention OR Account is PPE/intangibles)\n",
    "        \"CAPEX\": capex_amount(d)\n",
    "    }))\n",
    "\n",
    "    return out\n",
    "\n",
    "# Compute Indicators\n",
    "indicators = compute_indicators(gl_df)\n",
    "print(\"✅ Indicators computed:\")\n",
    "print(indicators)\n",
    "\n",
    "# Breakdown per class (useful for Power BI)\n",
    "class_per_year = (\n",
    "    gl_df.groupby([\"Year\", \"Class\"])[\"Amount\"]\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bc906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File created successfully → C:\\Users\\khali\\OneDrive\\Pictures\\Desktop\\financial_kpis.xlsx\n"
     ]
    }
   ],
   "source": [
    "# PART 5 - Save / Update Excel File \n",
    "\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def save_full_output(gl_df, class_per_year, indicators):\n",
    "    \"\"\"\n",
    "    Save everything in the Excel file:\n",
    "    - Enriched GL\n",
    "    - Class per Year\n",
    "    - Indicators\n",
    "    Optimized: adjust column width quickly + format date.\n",
    "    \"\"\"\n",
    "\n",
    "    # Format Date column\n",
    "    if \"Date\" in gl_df.columns:\n",
    "        gl_df[\"Date\"] = pd.to_datetime(gl_df[\"Date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "    # Save dataframes into Excel\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        gl_df.to_excel(writer, sheet_name=\"General_Ledger\", index=False)\n",
    "        class_per_year.to_excel(writer, sheet_name=\"Class_Per_Year\")\n",
    "        indicators.to_excel(writer, sheet_name=\"Indicators\")\n",
    "\n",
    "    # Re-open with openpyxl to adjust column widths\n",
    "    wb = load_workbook(OUTPUT_FILE)\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        for col in ws.columns:\n",
    "            max_length = 0\n",
    "            col_letter = col[0].column_letter\n",
    "            # Check only first 100 rows for performance\n",
    "            for cell in col[:100]:\n",
    "                if cell.value:\n",
    "                    max_length = max(max_length, len(str(cell.value)))\n",
    "            ws.column_dimensions[col_letter].width = min(max_length + 2, 40)\n",
    "    wb.save(OUTPUT_FILE)\n",
    "\n",
    "    print(f\"✅ File created successfully → {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "# Save everything\n",
    "save_full_output(gl_df, class_per_year, indicators)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
